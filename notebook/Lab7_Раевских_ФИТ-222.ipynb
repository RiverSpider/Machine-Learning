{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e03287c-c859-4650-973a-92f1ce816c40",
   "metadata": {},
   "source": [
    "Лабораторная работа №7. \"Полносвязные нейронные сети (многослойный персептрон). Решение задач регрессии и классификации\"\n",
    "\n",
    "Задание №1.\n",
    "Решить задачи регрессии и классификации на данных в соответствии с Вашим индивидуальным вариантом (см. Лаб.работы №3, 4), используя полносвязные НС; реализовать НС посредством API Keras и фреймворка TensorFlow; оценить качество полученных моделей с помощью метрик.\n",
    "\n",
    "Задание №2.\n",
    "Разработать многослойный персептрон (MLP), с помощью которого можно решать задачи регрессии и классификации. Предусмотреть возможность использования таких функции активации, как sigmoid, tanh и relu; также предусмотреть возможность указать, сколько слоев нужно, сколько на каждом из них нейронов и какую функцию активации должен иметь слой. Реализовать обучение MLP методом обратного распространения ошибки; самостоятельно найти производные функций sigmoid, tanh и relu; реализовать классический градиентный спуск с возможностью указания шага.\n",
    "\n",
    "\n",
    "Дополнительное Задание №3*.\n",
    "1. Самостоятельно изучить отличия работы оптимизаторов Adam и RMSProp от классического градиентного спуска.\n",
    "2. Реализовать градиентный спуск с использованием указанных оптимизаторов; предусмотрите возможность использования реализованных вами оптими-заторов в Вашем персептроне."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0be2f7a-5bbb-46ad-a6ad-99f9e3bbc29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "615615fa-6fb3-4a09-8eb8-1b29330188a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../data')\n",
    "#Вариант 1\n",
    "df_regression = pd.read_csv('lab3.csv')\n",
    "df_classifier = pd.read_csv('lab4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d739913-7796-4d0c-844b-ace3e2e18fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "numeric_features_classifier = ['time','length'] \n",
    "df_classifier[numeric_features_classifier] = scaler.fit_transform(df_classifier[numeric_features_classifier])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e6ccb60-242e-45d1-8930-0a945fae897e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y_classifier = df_classifier[\"delay\"]\n",
    "X_classifier = df_classifier.drop([\"delay\"], axis=1)\n",
    "X_classifier, _, y_classifier, _ = train_test_split(X_classifier, y_classifier, test_size=0.9, random_state=42)\n",
    "\n",
    "\n",
    "y_regression = df_regression[\"price(euro)\"]\n",
    "X_regression = df_regression.drop([\"price(euro)\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6a95915-41e8-4f40-9f8e-9f840c53c5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import NearMiss\n",
    "nm = NearMiss()\n",
    "X_classifier, y_classifier = nm.fit_resample(X_classifier, y_classifier.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f57e5a94-1905-466d-bdda-fd691d23003c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_classifier, X_test_classifier, y_train_classifier, y_test_classifier = train_test_split(X_classifier, y_classifier, test_size=0.2)\n",
    "X_train_regression, X_test_regression, y_train_regression, y_test_regression = train_test_split(X_regression, y_regression, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6decf4f7-f44c-4984-9bf5-aa6c76f6f9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# для оценки качества решения задачи регрессии\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "# для оценки качества решения задачи классификации\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "caeb8452-3858-4e15-9f0b-d74a97441236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2ea0cf2-42e4-4a50-9e9e-f1df3eb62e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "646187f6-0c37-4b24-a293-37e79f6cf271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем модель, как набор последовательных слоев\n",
    "model_regression = tf.keras.Sequential(\n",
    "    [\n",
    "        # Dense - полносвязный слой (каждый нейрон следующего слоя связан со всеми нейронами предыдущего)\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\", input_shape=(939,)),\n",
    "        # на втором скрытом слое будет 32 нейрона\n",
    "        tf.keras.layers.Dense(32, activation=\"linear\"),\n",
    "        # Dropout позволяет внести фактор случайности - при обучении часть нейронов будет отключаться\n",
    "        # каждый нейрон, в данном случае, будет отключаться с вероятностью 0.1\n",
    "        tf.keras.layers.Dropout(0.1),\n",
    "        tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.1),\n",
    "        # на выходе один нейрон, функция активации не применяется\n",
    "        tf.keras.layers.Dense(1, activation=\"linear\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d242b45-cc52-4428-8dd6-764bb6fe3244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                60160     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 62785 (245.25 KB)\n",
      "Trainable params: 62785 (245.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# посмотрим, какая сеть у нас получилась\n",
    "model_regression.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1ade7d3-3ad9-4980-a07b-0aab615ed296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# компилируем\n",
    "model_regression.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.005), loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "298eddab-de08-400c-ba64-2c0768802e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_regression = X_train_regression.astype('float32')\n",
    "y_train_regression = y_train_regression.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9cf4b3e6-962a-4701-baf5-4c00c407b30f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1fd57cc2b50>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# обучаем, 10 эпох означает 10 проходов по обучающей выборке\n",
    "model_regression.fit(X_train_regression, y_train_regression, epochs=50, verbose=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30bb8011-978b-49c0-8789-6ca98728ae06",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_regression = X_train_regression.astype('float32')\n",
    "y_test_regression = y_train_regression.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "590d2263-33be-4159-9e93-eff2ac30b365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "752/752 [==============================] - 1s 830us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_regression = model_regression.predict(X_test_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ee5a393-6645-43c4-8103-11fb33611f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2914.6333\n",
      "15697916.0\n",
      "0.4282546421316503\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "# оцениваем качество с помощью метрик\n",
    "print(mean_absolute_error(y_test_regression, y_pred_regression))\n",
    "print(mean_squared_error(y_test_regression, y_pred_regression))\n",
    "print(r2_score(y_test_regression, y_pred_regression))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ece31993-21e7-441f-ad8f-1c29827c5698",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Бинарная классификация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4beebfb5-9887-46f7-8ab9-8f3a5fca2bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_classification = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\", input_shape=(608,)),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.05),\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "        # используем 1 нейрон и sigmoid\n",
    "        tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1efb3060-8772-43eb-8aef-cd34a771e3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_classifier = X_train_classifier.astype('float32')\n",
    "y_train_classifier = y_train_classifier.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4806268b-98f6-4091-ba8a-20056cb89c83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1fd2f3a4110>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# в качестве функции активации используется бинарная  кроссэнтропия\n",
    "model_classification.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=\"mse\")\n",
    "# verbose=None - не будет логов\n",
    "model_classification.fit(X_train_classifier, y_train_classifier, epochs=100, verbose=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3532da2b-fdf5-46a0-a55e-e010cb25eb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_classifier = X_test_classifier.astype('float32')\n",
    "y_test_classifier = y_test_classifier.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c8299cfa-8666-48cc-98d8-e68fc392c7fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Предсказание на тестовых данных\u001b[39;00m\n\u001b[0;32m      2\u001b[0m y_pred_classifier \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39margmax(pred) \u001b[38;5;28;01mfor\u001b[39;00m pred \u001b[38;5;129;01min\u001b[39;00m model_classification\u001b[38;5;241m.\u001b[39mpredict(X_test_classifier, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)]\n\u001b[1;32m----> 3\u001b[0m y_pred_classes \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred_classifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\ML\\venv\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:1229\u001b[0m, in \u001b[0;36margmax\u001b[1;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[0;32m   1142\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;124;03mReturns the indices of the maximum values along an axis.\u001b[39;00m\n\u001b[0;32m   1144\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1226\u001b[0m \u001b[38;5;124;03m(2, 1, 4)\u001b[39;00m\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m kwds \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeepdims\u001b[39m\u001b[38;5;124m'\u001b[39m: keepdims} \u001b[38;5;28;01mif\u001b[39;00m keepdims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m-> 1229\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43margmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\ML\\venv\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:56\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     54\u001b[0m bound \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, method, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bound \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bound(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\Desktop\\ML\\venv\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:45\u001b[0m, in \u001b[0;36m_wrapit\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m     44\u001b[0m     wrap \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wrap:\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, mu\u001b[38;5;241m.\u001b[39mndarray):\n",
      "\u001b[1;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "# Предсказание на тестовых данных\n",
    "y_pred_classifier = [np.argmax(pred) for pred in model_classification.predict(X_test_classifier, verbose=None)]\n",
    "y_pred_classes = np.argmax(y_pred_classifier, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5558d69-6bce-43cb-854c-e1b920bfa90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test_classifier, y_pred_classifier)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7698d98-daee-4927-842d-64bd62cbf84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_classifier, y_pred_classifier, zero_division=0))\n",
    "print(confusion_matrix(y_test_classifier, y_pred_classifier))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d53cc9d-c85c-4187-a2a3-ab8c2aa07a47",
   "metadata": {},
   "source": [
    "Задание №2. Разработать многослойный персептрон (MLP), с помощью которого можно решать задачи регрессии и классификации. Предусмотреть возможность использования таких функции активации, как sigmoid, tanh и relu; также предусмотреть возможность указать, сколько слоев нужно, сколько на каждом из них нейронов и какую функцию активации должен иметь слой. Реализовать обучение MLP методом обратного распространения ошибки; самостоятельно найти производные функций sigmoid, tanh и relu; реализовать классический градиентный спуск с возможностью указания шага."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "103b1bc0-afcf-49c2-be89-77a014fb6dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "\n",
    "class MLP:\n",
    "    def __init__(self, input_size, hidden_layers, output_size, activations):\n",
    "        \"\"\"\n",
    "        :param input_size: Размер входного слоя\n",
    "        :param hidden_layers: Список, содержащий количество нейронов в каждом скрытом слое\n",
    "        :param output_size: Размер выходного слоя\n",
    "        :param activations: Список функций активации для каждого слоя\n",
    "        :param learning_rate: Скорость обучения для градиентного спуска\n",
    "        \"\"\"\n",
    "        self.input_size = input_size\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.output_size = output_size\n",
    "        self.activations = activations\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # Инициализация весов и смещений\n",
    "        self.weights, self.biases = self.initialize_parameters()\n",
    "\n",
    "    def initialize_parameters(self):\n",
    "        \"\"\"\n",
    "        Инициализация весов и смещений\n",
    "        \"\"\"\n",
    "        sizes = [self.input_size] + self.hidden_layers + [self.output_size]\n",
    "        weights = [np.random.randn(sizes[i], sizes[i+1]) for i in range(len(sizes)-1)]\n",
    "        biases = [np.zeros((1, sizes[i+1])) for i in range(len(sizes)-1)]\n",
    "        return weights, biases\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        \"\"\"\n",
    "        Сигмоидная функция активации\n",
    "        \"\"\"\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def sigmoid_derivative(self, x):\n",
    "        \"\"\"\n",
    "        Производная сигмоидной функции\n",
    "        \"\"\"\n",
    "        return self.sigmoid(x) * (1 - self.sigmoid(x))\n",
    "\n",
    "    def tanh(self, x):\n",
    "        \"\"\"\n",
    "        Гиперболический тангенс\n",
    "        \"\"\"\n",
    "        return np.tanh(x)\n",
    "\n",
    "    def tanh_derivative(self, x):\n",
    "        \"\"\"\n",
    "        Производная гиперболического тангенса\n",
    "        \"\"\"\n",
    "        return 1 - np.tanh(x)**2\n",
    "\n",
    "    def relu(self, x):\n",
    "        \"\"\"\n",
    "        Функция активации ReLU\n",
    "        \"\"\"\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def relu_derivative(self, x):\n",
    "        \"\"\"\n",
    "        Производная функции активации ReLU\n",
    "        \"\"\"\n",
    "        return np.where(x > 0, 1, 0)\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Прямое распространение (forward pass)\n",
    "        \"\"\"\n",
    "        self.z_values = []\n",
    "        self.activations_values = []\n",
    "\n",
    "        # Входной слой\n",
    "        a = X\n",
    "        self.activations_values.append(a)\n",
    "\n",
    "        # Скрытые слои\n",
    "        for i in range(len(self.hidden_layers)):\n",
    "            z = np.dot(a, self.weights[i]) + self.biases[i]\n",
    "            self.z_values.append(z)\n",
    "            a = self.activations[i](z)\n",
    "            self.activations_values.append(a)\n",
    "\n",
    "        # Выходной слой\n",
    "        z = np.dot(a, self.weights[-1]) + self.biases[-1]\n",
    "        self.z_values.append(z)\n",
    "        a = self.sigmoid(z)  # Для задачи регрессии можно использовать другие функции активации\n",
    "        self.activations_values.append(a)\n",
    "\n",
    "        return a\n",
    "\n",
    "    def backward(self, X, y):\n",
    "        \"\"\"\n",
    "        Обратное распространение ошибки (backpropagation)\n",
    "        \"\"\"\n",
    "        m = X.shape[0]\n",
    "        delta = self.activations_values[-1] - y\n",
    "        dz = delta * self.sigmoid_derivative(self.z_values[-1])\n",
    "        dw = np.dot(self.activations_values[-2].T, dz) / m\n",
    "        db = np.sum(dz, axis=0, keepdims=True) / m\n",
    "        self.weights[-1] -= self.learning_rate * dw\n",
    "        self.biases[-1] -= self.learning_rate * db\n",
    "\n",
    "        for i in range(len(self.hidden_layers), 0, -1):\n",
    "            delta = np.dot(dz, self.weights[i].T)\n",
    "            dz = delta * self.activations[i-1](self.z_values[i-1])\n",
    "            dw = np.dot(self.activations_values[i-2].T, dz) / m\n",
    "            db = np.sum(dz, axis=0, keepdims=True) / m\n",
    "            self.weights[i-1] -= self.learning_rate * dw\n",
    "            self.biases[i-1] -= self.learning_rate * db\n",
    "\n",
    "    def train(self, X, y, epochs):\n",
    "        \"\"\"\n",
    "        Обучение модели\n",
    "        \"\"\"\n",
    "        for epoch in range(epochs):\n",
    "            output = self.forward(X)\n",
    "            self.backward(X, y)\n",
    "\n",
    "            if epoch % 100 == 0:\n",
    "                loss = np.mean(0.5 * (output - y)**2)\n",
    "                print(f\"Epoch {epoch}, Loss: {loss}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Предсказание\n",
    "        \"\"\"\n",
    "        return self.forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "01fd0b41-f077-4bf8-b0a5-e868b7ae66e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data must be 1-dimensional, got ndarray of shape (24050, 24050) instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m mlp_regressor \u001b[38;5;241m=\u001b[39m MLP(input_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m939\u001b[39m, hidden_layers\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m24050\u001b[39m,\u001b[38;5;241m939\u001b[39m], output_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, activations\u001b[38;5;241m=\u001b[39m[np\u001b[38;5;241m.\u001b[39mtanh, expit])\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmlp_regressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_regression\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_regression\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[39], line 118\u001b[0m, in \u001b[0;36mMLP.train\u001b[1;34m(self, X, y, epochs)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m    117\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(X)\n\u001b[1;32m--> 118\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    121\u001b[0m         loss \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m (output \u001b[38;5;241m-\u001b[39m y)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "Cell \u001b[1;32mIn[39], line 97\u001b[0m, in \u001b[0;36mMLP.backward\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;124;03mОбратное распространение ошибки (backpropagation)\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     96\u001b[0m m \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 97\u001b[0m delta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactivations_values\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\n\u001b[0;32m     98\u001b[0m dz \u001b[38;5;241m=\u001b[39m delta \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigmoid_derivative(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz_values[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     99\u001b[0m dw \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivations_values[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mT, dz) \u001b[38;5;241m/\u001b[39m m\n",
      "File \u001b[1;32m~\\Desktop\\ML\\venv\\Lib\\site-packages\\pandas\\core\\generic.py:2102\u001b[0m, in \u001b[0;36mNDFrame.__array_ufunc__\u001b[1;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m   2098\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m   2099\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array_ufunc__\u001b[39m(\n\u001b[0;32m   2100\u001b[0m     \u001b[38;5;28mself\u001b[39m, ufunc: np\u001b[38;5;241m.\u001b[39mufunc, method: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39minputs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[0;32m   2101\u001b[0m ):\n\u001b[1;32m-> 2102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marraylike\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray_ufunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mufunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\ML\\venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:273\u001b[0m, in \u001b[0;36marray_ufunc\u001b[1;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    270\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m _standardize_out_kwarg(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    272\u001b[0m \u001b[38;5;66;03m# for binary ops, use our custom dunder methods\u001b[39;00m\n\u001b[1;32m--> 273\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mmaybe_dispatch_ufunc_to_dunder_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mufunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[0;32m    275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mops_dispatch.pyx:113\u001b[0m, in \u001b[0;36mpandas._libs.ops_dispatch.maybe_dispatch_ufunc_to_dunder_op\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\Desktop\\ML\\venv\\Lib\\site-packages\\pandas\\core\\ops\\common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\ML\\venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:198\u001b[0m, in \u001b[0;36mOpsMixin.__rsub__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__rsub__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__rsub__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m--> 198\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrsub\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\ML\\venv\\Lib\\site-packages\\pandas\\core\\series.py:5820\u001b[0m, in \u001b[0;36mSeries._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   5818\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_arith_method\u001b[39m(\u001b[38;5;28mself\u001b[39m, other, op):\n\u001b[0;32m   5819\u001b[0m     \u001b[38;5;28mself\u001b[39m, other \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_align_for_op(other)\n\u001b[1;32m-> 5820\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIndexOpsMixin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\ML\\venv\\Lib\\site-packages\\pandas\\core\\base.py:1383\u001b[0m, in \u001b[0;36mIndexOpsMixin._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   1380\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   1381\u001b[0m     result \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39marithmetic_op(lvalues, rvalues, op)\n\u001b[1;32m-> 1383\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_construct_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mres_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\ML\\venv\\Lib\\site-packages\\pandas\\core\\series.py:5916\u001b[0m, in \u001b[0;36mSeries._construct_result\u001b[1;34m(self, result, name)\u001b[0m\n\u001b[0;32m   5913\u001b[0m \u001b[38;5;66;03m# TODO: result should always be ArrayLike, but this fails for some\u001b[39;00m\n\u001b[0;32m   5914\u001b[0m \u001b[38;5;66;03m#  JSONArray tests\u001b[39;00m\n\u001b[0;32m   5915\u001b[0m dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(result, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m-> 5916\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_constructor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   5917\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   5919\u001b[0m \u001b[38;5;66;03m# Set the result's name after __finalize__ is called because __finalize__\u001b[39;00m\n\u001b[0;32m   5920\u001b[0m \u001b[38;5;66;03m#  would set it back to self.name\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\ML\\venv\\Lib\\site-packages\\pandas\\core\\series.py:512\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    510\u001b[0m         data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 512\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43msanitize_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    514\u001b[0m     manager \u001b[38;5;241m=\u001b[39m get_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.data_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    515\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\Desktop\\ML\\venv\\Lib\\site-packages\\pandas\\core\\construction.py:636\u001b[0m, in \u001b[0;36msanitize_array\u001b[1;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[0;32m    633\u001b[0m             subarr \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, subarr)\n\u001b[0;32m    634\u001b[0m             subarr \u001b[38;5;241m=\u001b[39m maybe_infer_to_datetimelike(subarr)\n\u001b[1;32m--> 636\u001b[0m subarr \u001b[38;5;241m=\u001b[39m \u001b[43m_sanitize_ndim\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_2d\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(subarr, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    639\u001b[0m     \u001b[38;5;66;03m# at this point we should have dtype be None or subarr.dtype == dtype\u001b[39;00m\n\u001b[0;32m    640\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mdtype, dtype)\n",
      "File \u001b[1;32m~\\Desktop\\ML\\venv\\Lib\\site-packages\\pandas\\core\\construction.py:695\u001b[0m, in \u001b[0;36m_sanitize_ndim\u001b[1;34m(result, data, dtype, index, allow_2d)\u001b[0m\n\u001b[0;32m    693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m allow_2d:\n\u001b[0;32m    694\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m--> 695\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    696\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData must be 1-dimensional, got ndarray of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    697\u001b[0m     )\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(dtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, ExtensionDtype):\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# i.e. NumpyEADtype(\"O\")\u001b[39;00m\n\u001b[0;32m    701\u001b[0m     result \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39masarray_tuplesafe(data, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[1;31mValueError\u001b[0m: Data must be 1-dimensional, got ndarray of shape (24050, 24050) instead"
     ]
    }
   ],
   "source": [
    "mlp_regressor = MLP(input_size=939, hidden_layers=[24050,939], output_size=1, activations=[np.tanh, expit])\n",
    "mlp_regressor.train(X_train_regression, y_train_regression, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c0cde8cb-51a0-4ff4-abf4-2d92f79c15fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Максимальное количество голов крупного рогатого скота за указанный период составляет:  414\n"
     ]
    }
   ],
   "source": [
    "def find_max_cattle_population():\n",
    "    initial_cattle_population = 74\n",
    "    initial_wolf_population = 67\n",
    "    wolf_shooting = 36\n",
    "    final_wolf_population = 44\n",
    "    final_cattle_population = 107\n",
    "\n",
    "    # Расчет максимальной численности скота\n",
    "    max_cattle_population = (final_cattle_population * (initial_wolf_population - wolf_shooting)) / (final_wolf_population - wolf_shooting)\n",
    "\n",
    "    return int(max_cattle_population)\n",
    "\n",
    "# Вызов функции и вывод результата\n",
    "result = find_max_cattle_population()\n",
    "print(\"Максимальное количество голов крупного рогатого скота за указанный период составляет: \", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "496371e2-70b3-430c-8a99-ef82192715b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение потенциала в центре конденсатора: 5.6 В\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.constants import epsilon_0\n",
    "\n",
    "# Дано\n",
    "V0 = 5.0  # Напряжение на обкладках в вольтах\n",
    "D = 0.4e-3  # Расстояние между обкладками в метрах\n",
    "p0 = 1e4  # Объемная плотность заряда p0 в кл/м^5\n",
    "e = 4.04e-12  # Диэлектрическая проницаемость в Ф/м\n",
    "N = 1000  # Количество точек для аппроксимации\n",
    "\n",
    "# Шаг по координате X\n",
    "dx = D / N\n",
    "\n",
    "# Инициализация массива для хранения значений потенциала\n",
    "phi = np.zeros(N)\n",
    "\n",
    "# Задание начальных и граничных условий\n",
    "phi[0] = 0  # Потенциал на заземленной обкладке\n",
    "phi[-1] = V0  # Потенциал на поданной напряжением обкладке\n",
    "\n",
    "# Аппроксимация дифференциального уравнения методом конечных разностей\n",
    "for i in range(1, N - 1):\n",
    "    x = i * dx\n",
    "    p_x = p0 * (x - D) ** 2\n",
    "    phi[i + 1] = 2 * phi[i] - phi[i - 1] + (dx ** 2) * p_x / e\n",
    "\n",
    "# Находим значение потенциала в центре конденсатора\n",
    "phi_center = phi[N // 2]\n",
    "\n",
    "# Вывод результата\n",
    "print(f\"Значение потенциала в центре конденсатора: {phi_center:.1f} В\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6118d4a-4da3-4a4d-b508-8760cc918bab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
