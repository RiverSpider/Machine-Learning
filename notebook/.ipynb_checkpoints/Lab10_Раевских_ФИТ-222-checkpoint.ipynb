{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3282eabb-34a5-450a-b90d-9719461e0d1c",
   "metadata": {},
   "source": [
    "Лабораторная работа №10. ОСНОВЫ ОБРАБОТКИ ЕСТЕСТВЕННОГО ЯЗЫКА (NLP). ЗАДАЧА ТЕМАТИЧЕСКОГО МОДЕЛИРОВАНИЯ\n",
    "\n",
    "ЗАДАНИЕ\n",
    "1. Для выполнения задания используйте датасет с данными о спаме (https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset).\n",
    "2. Самостоятельно реализовать BoW, TF-IDF.\n",
    "3. Решить задачу классификации с понижением размерности.\n",
    " Использовать самостоятельно реализованные модели из предыдущих ЛР.\n",
    "4. Решить задачу тематического моделирования с помощью LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0387d4b1-7f31-457e-89b5-0002a90c0616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "os.chdir('../data')\n",
    "df = pd.read_csv('spam.csv', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c95d3653-0c88-4751-a6a7-d020d4714d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   v1          5572 non-null   object\n",
      " 1   v2          5572 non-null   object\n",
      " 2   Unnamed: 2  50 non-null     object\n",
      " 3   Unnamed: 3  12 non-null     object\n",
      " 4   Unnamed: 4  6 non-null      object\n",
      "dtypes: object(5)\n",
      "memory usage: 217.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b03043e6-b875-45a4-a9d2-b5dc8da57e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0729974-8827-4ecb-b6de-58840fdf488f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Unnamed: 2', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdcfdb64-d792-4dd8-8143-fd7963d95e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Unnamed: 3', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7229cd2-4fc5-41e0-a402-7d62146cd78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Unnamed: 4', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e77ffe9-1b35-47ee-82f4-dc01872fed56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   v1      5572 non-null   object\n",
      " 1   v2      5572 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e67a087-b313-4328-946b-8040101cb9ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop_duplicates().reset_index(drop=True)\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "55643fcc-0be9-484f-9878-6dc9e2993041",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['v2']\n",
    "y = df['v1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d4218aaf-6044-49a6-a2f6-dbdfa2defa47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5975f2a8-9593-46fc-824e-bf91c5f92ca6",
   "metadata": {},
   "source": [
    "# Самостоятельно реализовать BoW, TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "54648009-7845-499c-b992-864cf496b7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "81d6490f-bd69-4634-80c3-2581883c631e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание экземпляра CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Преобразование текстовых данных в матрицу признаков\n",
    "X_bow = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1dbf2ae2-e995-4b06-9ed5-5080b8d1ff5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение на тренировочный и тестовый наборы данных\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_bow, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "70bdd577-c4ec-4b20-be77-fee82989d7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9787234042553191\n"
     ]
    }
   ],
   "source": [
    "# Обучение и оценка модели\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "28caf53f-618d-4f58-b89a-8f8372764747",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Создание экземпляра TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Преобразование текстовых данных в матрицу признаков\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(X)\n",
    "\n",
    "# Разделение на тренировочный и тестовый наборы данных\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6f93a2f8-4c6d-41df-a9ad-609ee7e18810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9555125725338491\n"
     ]
    }
   ],
   "source": [
    "# Обучение и оценка модели\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710cfe9a-c82c-49ff-b518-aab9918f2114",
   "metadata": {},
   "source": [
    "# Решить задачу классификации с понижением размерности. Использовать самостоятельно реализованные модели из предыдущих ЛР."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5d8d7c9f-b155-4110-b4c5-86c844ca3dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, RFE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE, Isomap\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b3447bad-6c4b-457f-aa06-d22510a1f6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_class(X, y):\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "  bag = BaggingClassifier().fit(X_train, y_train)\n",
    "  print(classification_report(y_test, bag.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "024dff6e-1e74-4147-8bac-ff307f2b3eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. SelectKBest\n",
    "selector = SelectKBest(k=2)  # количество наиболее значимых признаков\n",
    "X_SelectKBest_classifier1 = selector.fit_transform(X_bow, y)\n",
    "X_SelectKBest_classifier2 = selector.fit_transform(X_tfidf, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f734eb57-e408-44ca-97e4-c0dd2b041448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.95      0.96      0.96       917\n",
      "        spam       0.66      0.60      0.63       117\n",
      "\n",
      "    accuracy                           0.92      1034\n",
      "   macro avg       0.80      0.78      0.79      1034\n",
      "weighted avg       0.92      0.92      0.92      1034\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_class(X_SelectKBest_classifier1, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "154580c5-a044-4810-ac29-92f3222d081b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.91      1.00      0.95       917\n",
      "        spam       0.90      0.24      0.38       117\n",
      "\n",
      "    accuracy                           0.91      1034\n",
      "   macro avg       0.91      0.62      0.67      1034\n",
      "weighted avg       0.91      0.91      0.89      1034\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_class(X_SelectKBest_classifier2, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "813c99be-b9e2-4767-a881-9b1993a45290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. RFE (Recursive Feature Elimination)\n",
    "estimator = BaggingClassifier()\n",
    "selector = RFE(estimator, n_features_to_select=5)  # количество выбранных признаков (n_features_to_select)\n",
    "X_RFE_classifier1 = selector.fit_transform(X_SelectKBest_classifier1, y)\n",
    "X_RFE_classifier2 = selector.fit_transform(X_SelectKBest_classifier2, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "db5a5927-d228-444f-9e70-9b2b8637bf4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.95      0.96      0.96       917\n",
      "        spam       0.66      0.60      0.63       117\n",
      "\n",
      "    accuracy                           0.92      1034\n",
      "   macro avg       0.80      0.78      0.79      1034\n",
      "weighted avg       0.92      0.92      0.92      1034\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_class(X_RFE_classifier1, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5766b6e0-2db7-46d9-94fc-1353f5c243d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.91      1.00      0.95       917\n",
      "        spam       0.90      0.24      0.38       117\n",
      "\n",
      "    accuracy                           0.91      1034\n",
      "   macro avg       0.91      0.62      0.67      1034\n",
      "weighted avg       0.91      0.91      0.89      1034\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_class(X_RFE_classifier2, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "118243f7-437a-442e-8141-cf57b9ae308a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raevs\\Desktop\\ML\\venv\\Lib\\site-packages\\sklearn\\manifold\\_isomap.py:383: UserWarning: The number of connected components of the neighbors graph is 6 > 1. Completing the graph to fit Isomap might be slow. Increase the number of neighbors to avoid this issue.\n",
      "  self._fit_transform(X)\n",
      "C:\\Users\\raevs\\Desktop\\ML\\venv\\Lib\\site-packages\\scipy\\sparse\\_index.py:100: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "C:\\Users\\raevs\\Desktop\\ML\\venv\\Lib\\site-packages\\sklearn\\manifold\\_isomap.py:383: UserWarning: The number of connected components of the neighbors graph is 4 > 1. Completing the graph to fit Isomap might be slow. Increase the number of neighbors to avoid this issue.\n",
      "  self._fit_transform(X)\n",
      "C:\\Users\\raevs\\Desktop\\ML\\venv\\Lib\\site-packages\\scipy\\sparse\\_index.py:100: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n"
     ]
    }
   ],
   "source": [
    "# 6. Isomap\n",
    "isomap = Isomap(n_components=10)  # количество компонент (n_components)\n",
    "X_Isomap_classifier1 = isomap.fit_transform(X_bow)\n",
    "X_Isomap_classifier2 = isomap.fit_transform(X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "36846aa0-3452-472e-a825-a03424bf4f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.95      0.98      0.96       917\n",
      "        spam       0.76      0.56      0.65       117\n",
      "\n",
      "    accuracy                           0.93      1034\n",
      "   macro avg       0.85      0.77      0.80      1034\n",
      "weighted avg       0.92      0.93      0.93      1034\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_class(X_Isomap_classifier1, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "51bc5b8c-9abb-4c20-975b-24d0d98c5e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.93      0.97      0.95       917\n",
      "        spam       0.65      0.45      0.53       117\n",
      "\n",
      "    accuracy                           0.91      1034\n",
      "   macro avg       0.79      0.71      0.74      1034\n",
      "weighted avg       0.90      0.91      0.90      1034\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_class(X_Isomap_classifier2, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724e206f-7de5-4c0e-bd89-dace6cdb2d1c",
   "metadata": {},
   "source": [
    "# Решить задачу тематического моделирования с помощью LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4df70570-b3ef-4576-b31d-9165b8bce63b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[73], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m corpora\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gensim'"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim import models\n",
    "from gensim import corpora\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "18914aad-14ff-4bc8-873c-fe3bec2532b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предобработка текстовых данных\n",
    "def preprocess_text(text):\n",
    "    # Приведение текста к нижнему регистру\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Удаление пунктуации и специальных символов\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    \n",
    "    # Токенизация текста\n",
    "    tokens = text.split()\n",
    "    \n",
    "    # Удаление стоп-слов\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Лемматизация\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bdb5fc1b-7ea5-4c53-ab0e-8dcd774aef90",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 're' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Подготовка данных\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m preprocessed_data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mpreprocess_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m]\u001b[49m\n",
      "Cell \u001b[1;32mIn[75], line 2\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Подготовка данных\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m preprocessed_data \u001b[38;5;241m=\u001b[39m [\u001b[43mpreprocess_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m X]\n",
      "Cell \u001b[1;32mIn[74], line 7\u001b[0m, in \u001b[0;36mpreprocess_text\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      4\u001b[0m text \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39mlower()\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Удаление пунктуации и специальных символов\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[43mre\u001b[49m\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m, text)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Токенизация текста\u001b[39;00m\n\u001b[0;32m     10\u001b[0m tokens \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39msplit()\n",
      "\u001b[1;31mNameError\u001b[0m: name 're' is not defined"
     ]
    }
   ],
   "source": [
    "# Подготовка данных\n",
    "preprocessed_data = [preprocess_text(text) for text in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1572bcc8-db1f-47a5-a8c5-77b784a426c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'corpora' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Создание словаря\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m dictionary \u001b[38;5;241m=\u001b[39m \u001b[43mcorpora\u001b[49m\u001b[38;5;241m.\u001b[39mDictionary(preprocessed_data)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'corpora' is not defined"
     ]
    }
   ],
   "source": [
    "# Создание словаря\n",
    "dictionary = corpora.Dictionary(preprocessed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5026832e-dfe6-4552-96f7-bbab3d5f5f68",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocessed_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[77], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Преобразование текстов в мешок слов (Bag-of-words)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m bow_corpus \u001b[38;5;241m=\u001b[39m [dictionary\u001b[38;5;241m.\u001b[39mdoc2bow(text) \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m \u001b[43mpreprocessed_data\u001b[49m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'preprocessed_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Преобразование текстов в мешок слов (Bag-of-words)\n",
    "bow_corpus = [dictionary.doc2bow(text) for text in preprocessed_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "452b40ed-6496-4d9d-a529-3ba29d89c1d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[78], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Создание модели LDA\u001b[39;00m\n\u001b[0;32m      2\u001b[0m num_topics \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m  \u001b[38;5;66;03m# Количество тем\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m lda_model \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m\u001b[38;5;241m.\u001b[39mLdaModel(bow_corpus, num_topics\u001b[38;5;241m=\u001b[39mnum_topics, id2word\u001b[38;5;241m=\u001b[39mdictionary, passes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'models' is not defined"
     ]
    }
   ],
   "source": [
    "# Создание модели LDA\n",
    "num_topics = 5  # Количество тем\n",
    "lda_model = models.LdaModel(bow_corpus, num_topics=num_topics, id2word=dictionary, passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "57634a93-0a2a-4f68-b3fa-62c79059c7a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lda_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[79], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Анализ результатов\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m topics \u001b[38;5;241m=\u001b[39m \u001b[43mlda_model\u001b[49m\u001b[38;5;241m.\u001b[39mprint_topics(num_topics\u001b[38;5;241m=\u001b[39mnum_topics)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m topic \u001b[38;5;129;01min\u001b[39;00m topics:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(topic)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lda_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Анализ результатов\n",
    "topics = lda_model.print_topics(num_topics=num_topics)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "57b171e3-6f03-4865-af6d-3aa59f28e73f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lda_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[80], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Получение вероятных слов для каждой темы\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m top_words \u001b[38;5;241m=\u001b[39m \u001b[43mlda_model\u001b[49m\u001b[38;5;241m.\u001b[39mshow_topics(num_topics\u001b[38;5;241m=\u001b[39mnum_topics, num_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m topic_words \u001b[38;5;129;01min\u001b[39;00m top_words:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(topic_words)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lda_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Получение вероятных слов для каждой темы\n",
    "top_words = lda_model.show_topics(num_topics=num_topics, num_words=10)\n",
    "for topic_words in top_words:\n",
    "    print(topic_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c58cc8-8969-43d6-8f59-292ac8135804",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
