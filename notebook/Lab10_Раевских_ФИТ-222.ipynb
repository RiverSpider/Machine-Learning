{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3282eabb-34a5-450a-b90d-9719461e0d1c",
   "metadata": {},
   "source": [
    "Лабораторная работа №10. ОСНОВЫ ОБРАБОТКИ ЕСТЕСТВЕННОГО ЯЗЫКА (NLP). ЗАДАЧА ТЕМАТИЧЕСКОГО МОДЕЛИРОВАНИЯ\n",
    "\n",
    "ЗАДАНИЕ\n",
    "1. Для выполнения задания используйте датасет с данными о спаме (https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset).\n",
    "2. Самостоятельно реализовать BoW, TF-IDF.\n",
    "3. Решить задачу классификации с понижением размерности.\n",
    " Использовать самостоятельно реализованные модели из предыдущих ЛР.\n",
    "4. Решить задачу тематического моделирования с помощью LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0387d4b1-7f31-457e-89b5-0002a90c0616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "os.chdir('../data')\n",
    "df = pd.read_csv('spam.csv', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c95d3653-0c88-4751-a6a7-d020d4714d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   v1          5572 non-null   object\n",
      " 1   v2          5572 non-null   object\n",
      " 2   Unnamed: 2  50 non-null     object\n",
      " 3   Unnamed: 3  12 non-null     object\n",
      " 4   Unnamed: 4  6 non-null      object\n",
      "dtypes: object(5)\n",
      "memory usage: 217.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b03043e6-b875-45a4-a9d2-b5dc8da57e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0729974-8827-4ecb-b6de-58840fdf488f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Unnamed: 2', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdcfdb64-d792-4dd8-8143-fd7963d95e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Unnamed: 3', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7229cd2-4fc5-41e0-a402-7d62146cd78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Unnamed: 4', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e77ffe9-1b35-47ee-82f4-dc01872fed56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   v1      5572 non-null   object\n",
      " 1   v2      5572 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e67a087-b313-4328-946b-8040101cb9ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop_duplicates().reset_index(drop=True)\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55643fcc-0be9-484f-9878-6dc9e2993041",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['v2']\n",
    "y = df['v1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4218aaf-6044-49a6-a2f6-dbdfa2defa47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5975f2a8-9593-46fc-824e-bf91c5f92ca6",
   "metadata": {},
   "source": [
    "# Самостоятельно реализовать BoW, TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54648009-7845-499c-b992-864cf496b7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81d6490f-bd69-4634-80c3-2581883c631e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание экземпляра CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Преобразование текстовых данных в матрицу признаков\n",
    "X_bow = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1dbf2ae2-e995-4b06-9ed5-5080b8d1ff5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение на тренировочный и тестовый наборы данных\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_bow, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70bdd577-c4ec-4b20-be77-fee82989d7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9787234042553191\n"
     ]
    }
   ],
   "source": [
    "# Обучение и оценка модели\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28caf53f-618d-4f58-b89a-8f8372764747",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Создание экземпляра TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Преобразование текстовых данных в матрицу признаков\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(X)\n",
    "\n",
    "# Разделение на тренировочный и тестовый наборы данных\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f93a2f8-4c6d-41df-a9ad-609ee7e18810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9555125725338491\n"
     ]
    }
   ],
   "source": [
    "# Обучение и оценка модели\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c18eea5b-85e2-4259-954d-f13481a85f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(corpus):\n",
    "    # создается множество unique_words, которое содержит все уникальные слова, встречающиеся в документах\n",
    "    unique_words = set(word for doc in corpus for word in doc.split())\n",
    "    # создается словарь, в котором каждому уникальному слову присваивается уникальный индекс\n",
    "    # enumerate возвращает индекс и значение каждого элемента в объекте\n",
    "    word_dict = {word: i for i, word in enumerate(unique_words)}\n",
    "    # создается пустой список bow_corpus, который впоследствии будет заполнен векторами BoW для каждого документа\n",
    "    bow_corpus = []\n",
    "    # цикл проходит через каждый документ\n",
    "    for doc in corpus:\n",
    "        # создается список word_count, длиной равной количеству уникальных слов, и заполняется нулями\n",
    "        word_count = [0] * len(unique_words)\n",
    "        # вложенный цикл проходит через каждое слово в документе\n",
    "        for word in doc.split():\n",
    "            # увеличивается счетчик для текущего слова в списке word_count. Индекс для увеличения счетчика берется из word_dict\n",
    "            word_count[word_dict[word]] += 1\n",
    "        # вектор частот слов, представленный списком word_count, добавляется в bow_corpus\n",
    "        bow_corpus.append(word_count)\n",
    "    # возвращает два значения: bow_corpus, который представляет собой список векторов BoW для каждого документа,\n",
    "    # и word_dict, который представляет собой словарь уникальных слов и их индексов.\n",
    "    return bow_corpus, word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "288f24d8-98d7-4b9f-890b-80eab2543d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def tf_idf(corpus):\n",
    "    # функция bag_of_words применяется к корпусу, возвращая список векторов bag-of-words и словарь, сопоставляющий каждому уникальному слову его индекс\n",
    "    bow_corpus, word_dict = bag_of_words(corpus)\n",
    "    # вычисляет количество документов в корпусе\n",
    "    num_docs = len(corpus)\n",
    "    # создается пустой список для хранения векторов\n",
    "    tf_idf_corpus = []\n",
    "    \n",
    "    # создается список, заполненный нулями, для подсчета, в скольких документах встречается каждое слово\n",
    "    word_document_count = [0] * len(word_dict)\n",
    "    # цикл проходит через все документы и увеличивает счетчик для каждого слова, которое встречается в документе\n",
    "    for word_count in bow_corpus:\n",
    "        for i, count in enumerate(word_count):\n",
    "            if count > 0:\n",
    "                word_document_count[i] += 1\n",
    "\n",
    "    # цикл проходит через все документы второй раз\n",
    "    for word_count in bow_corpus:\n",
    "        # создается пустой список для хранения вектора TF-IDF для текущего документа\n",
    "        tf_idf_vector = []\n",
    "        # цикл проходит через все слова в текущем документе и вычисляет их значения TF и IDF. \n",
    "        # значение TF-IDF для каждого слова затем добавляется в вектор TF-IDF для текущего документа\n",
    "        for i, count in enumerate(word_count):\n",
    "            # вычисляется значение TF для текущего слова. \n",
    "            # TF — это просто отношение количества вхождений слова в документе к общему числу слов в документе.\n",
    "            tf = count / (sum(word_count) + 1e-10)\n",
    "            # вычисляется значение IDF для текущего слова. \n",
    "            # IDF вычисляется как логарифм отношения общего числа документов к числу документов, содержащих данное слово.\n",
    "            idf = math.log(num_docs / (1 + word_document_count[i])\n",
    "            tf_idf_vector.append(tf * idf)\n",
    "        # вектор TF-IDF для текущего документа добавляется в список всех векторов TF-IDF\n",
    "        tf_idf_corpus.append(tf_idf_vector)\n",
    "    # возвращает список всех векторов TF-IDF и словарь, сопоставляющий каждому уникальному слову его индекс\n",
    "    return tf_idf_corpus, word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d99fa06-bb70-4cc6-b188-a2d15d903bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06ba7c2b-08eb-43bf-b89b-c317ec5c0066",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.str.replace('[^\\w\\s]', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6862468-e4e9-4b56-b7ef-bdccf87c0ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "X = X.apply(lambda x: ' '.join([word for word in x.split() if word not in stop]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c3ce1f-cbf3-4b75-b572-35e6637057dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc9216eb-17ef-4622-932a-9977486c22ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bow, word_dictBOW = bag_of_words(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8d57565-a276-4d75-8bf7-c919f1173e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tf_idf, word_dictTF = tf_idf(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "18eac92f-e70d-4968-b457-addd02e34836",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X_bow, y, test_size=0.2, random_state=42)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_tf_idf, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41a3ed43-4394-442d-9ae1-885ac4c186d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9787234042553191\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train1, y_train1)\n",
    "y_pred = model.predict(X_test1)\n",
    "accuracy = accuracy_score(y_test1, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "950633f6-0075-4447-98c8-a20d8a521d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9632495164410058\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train2, y_train2)\n",
    "y_pred = model.predict(X_test2)\n",
    "accuracy = accuracy_score(y_test2, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710cfe9a-c82c-49ff-b518-aab9918f2114",
   "metadata": {},
   "source": [
    "# Решить задачу классификации с понижением размерности. Использовать самостоятельно реализованные модели из предыдущих ЛР."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d8d7c9f-b155-4110-b4c5-86c844ca3dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, RFE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE, Isomap\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3447bad-6c4b-457f-aa06-d22510a1f6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_class(X, y):\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "  bag = BaggingClassifier().fit(X_train, y_train)\n",
    "  print(classification_report(y_test, bag.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "024dff6e-1e74-4147-8bac-ff307f2b3eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. SelectKBest\n",
    "selector = SelectKBest(k=2)  # количество наиболее значимых признаков\n",
    "X_SelectKBest_classifier1 = selector.fit_transform(X_bow, y)\n",
    "X_SelectKBest_classifier2 = selector.fit_transform(X_tfidf, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f734eb57-e408-44ca-97e4-c0dd2b041448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.95      0.96      0.96       917\n",
      "        spam       0.66      0.60      0.63       117\n",
      "\n",
      "    accuracy                           0.92      1034\n",
      "   macro avg       0.80      0.78      0.79      1034\n",
      "weighted avg       0.92      0.92      0.92      1034\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_class(X_SelectKBest_classifier1, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "154580c5-a044-4810-ac29-92f3222d081b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.91      1.00      0.95       917\n",
      "        spam       0.90      0.24      0.38       117\n",
      "\n",
      "    accuracy                           0.91      1034\n",
      "   macro avg       0.91      0.62      0.67      1034\n",
      "weighted avg       0.91      0.91      0.89      1034\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_class(X_SelectKBest_classifier2, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "813c99be-b9e2-4767-a881-9b1993a45290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. RFE (Recursive Feature Elimination)\n",
    "estimator = BaggingClassifier()\n",
    "selector = RFE(estimator, n_features_to_select=5)  # количество выбранных признаков (n_features_to_select)\n",
    "X_RFE_classifier1 = selector.fit_transform(X_SelectKBest_classifier1, y)\n",
    "X_RFE_classifier2 = selector.fit_transform(X_SelectKBest_classifier2, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db5a5927-d228-444f-9e70-9b2b8637bf4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.95      0.96      0.96       917\n",
      "        spam       0.66      0.60      0.63       117\n",
      "\n",
      "    accuracy                           0.92      1034\n",
      "   macro avg       0.80      0.78      0.79      1034\n",
      "weighted avg       0.92      0.92      0.92      1034\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_class(X_RFE_classifier1, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5766b6e0-2db7-46d9-94fc-1353f5c243d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.91      1.00      0.95       917\n",
      "        spam       0.90      0.24      0.38       117\n",
      "\n",
      "    accuracy                           0.91      1034\n",
      "   macro avg       0.91      0.62      0.67      1034\n",
      "weighted avg       0.91      0.91      0.89      1034\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_class(X_RFE_classifier2, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "118243f7-437a-442e-8141-cf57b9ae308a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raevs\\Desktop\\ML\\venv\\Lib\\site-packages\\sklearn\\manifold\\_isomap.py:383: UserWarning: The number of connected components of the neighbors graph is 6 > 1. Completing the graph to fit Isomap might be slow. Increase the number of neighbors to avoid this issue.\n",
      "  self._fit_transform(X)\n",
      "C:\\Users\\raevs\\Desktop\\ML\\venv\\Lib\\site-packages\\scipy\\sparse\\_index.py:100: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "C:\\Users\\raevs\\Desktop\\ML\\venv\\Lib\\site-packages\\sklearn\\manifold\\_isomap.py:383: UserWarning: The number of connected components of the neighbors graph is 4 > 1. Completing the graph to fit Isomap might be slow. Increase the number of neighbors to avoid this issue.\n",
      "  self._fit_transform(X)\n",
      "C:\\Users\\raevs\\Desktop\\ML\\venv\\Lib\\site-packages\\scipy\\sparse\\_index.py:100: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n"
     ]
    }
   ],
   "source": [
    "# 6. Isomap\n",
    "isomap = Isomap(n_components=10)  # количество компонент (n_components)\n",
    "X_Isomap_classifier1 = isomap.fit_transform(X_bow)\n",
    "X_Isomap_classifier2 = isomap.fit_transform(X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36846aa0-3452-472e-a825-a03424bf4f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.94      0.97      0.95       917\n",
      "        spam       0.69      0.52      0.59       117\n",
      "\n",
      "    accuracy                           0.92      1034\n",
      "   macro avg       0.81      0.75      0.77      1034\n",
      "weighted avg       0.91      0.92      0.91      1034\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_class(X_Isomap_classifier1, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "51bc5b8c-9abb-4c20-975b-24d0d98c5e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.93      0.97      0.95       917\n",
      "        spam       0.62      0.41      0.49       117\n",
      "\n",
      "    accuracy                           0.90      1034\n",
      "   macro avg       0.77      0.69      0.72      1034\n",
      "weighted avg       0.89      0.90      0.90      1034\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_class(X_Isomap_classifier2, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724e206f-7de5-4c0e-bd89-dace6cdb2d1c",
   "metadata": {},
   "source": [
    "# Решить задачу тематического моделирования с помощью LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4df70570-b3ef-4576-b31d-9165b8bce63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\raevs\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim import corpora\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d90cc495-f298-4aaa-826d-80a75eea9d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание объекта CountVectorizer для извлечения признаков\n",
    "vectorizer = CountVectorizer(max_features=1000,   # Ограничение на максимальное количество признаков\n",
    "                             stop_words='english',  # Игнорирование стоп-слов\n",
    "                             max_df=0.5,  # Игнорирование терминов, которые появляются в более чем 50% документов\n",
    "                             min_df=2)  # Игнорирование терминов, которые появляются в менее чем 2 документах\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3627e32b-611d-46a0-8142-e8a4991e1dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразование текстовых данных в матрицу признаков\n",
    "X_features = vectorizer.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "34ee35d3-4ad1-45e3-a53f-f8d3eebae0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание модели LDA\n",
    "num_topics = 10  # Количество тем\n",
    "lda_model = LatentDirichletAllocation(n_components=num_topics, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "44e2e6ee-4644-4d95-a98e-2a5005aa1be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение модели LDA\n",
    "lda_model.fit(X_features)\n",
    "\n",
    "# Получение самых вероятных слов для каждой темы\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "top_words = 10  # Количество верхних слов для вывода"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aab9ce0a-926c-4bdf-b14c-a97a1722a53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тема #1:\n",
      "['know', 'did', 'right', 'yes', 'just', 'tonight', 'say', 'gonna', 'phone', 'like']\n",
      "\n",
      "Тема #2:\n",
      "['lor', 'got', 'ok', 'oh', 'wat', 'pls', 'dun', 'wan', 'ask', 'ìï']\n",
      "\n",
      "Тема #3:\n",
      "['tell', 'just', 'don', 'yeah', 'sure', 'time', 'got', 'ok', 'going', 'll']\n",
      "\n",
      "Тема #4:\n",
      "['like', 'going', 'da', 'way', 'feel', 'think', 'time', 'ya', 'life', 'make']\n",
      "\n",
      "Тема #5:\n",
      "['claim', 'prize', 'won', 'number', 'cash', 'www', 'urgent', 'win', 'com', 'txt']\n",
      "\n",
      "Тема #6:\n",
      "['good', 'love', 'day', 'ì_', 'hi', 'hope', 'happy', 'morning', 'babe', 'miss']\n",
      "\n",
      "Тема #7:\n",
      "['ll', 'just', 'sorry', 'need', 'want', 'come', 'sent', 'dont', 'later', 'time']\n",
      "\n",
      "Тема #8:\n",
      "['txt', 'home', 'new', 'ur', 'chat', '150p', 'send', 'stop', 'week', 'free']\n",
      "\n",
      "Тема #9:\n",
      "['gt', 'lt', 'ur', 'ok', 'reply', 'msg', 'send', 'sms', 'heart', 'text']\n",
      "\n",
      "Тема #10:\n",
      "['free', 'text', 'know', 'mobile', 'stop', 'let', 'phone', 'reply', 'aight', 'txt']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for topic_idx, topic in enumerate(lda_model.components_):\n",
    "    top_feature_indices = topic.argsort()[:-top_words - 1:-1]\n",
    "    top_features = [feature_names[i] for i in top_feature_indices]\n",
    "    print(f\"Тема #{topic_idx + 1}:\")\n",
    "    print(top_features)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b48f9489-00cc-47e5-bb29-46877c9549ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получение распределения тем для каждого документа\n",
    "topic_distribution = lda_model.transform(X_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5899e2f7-e707-4216-9c5a-4eab10400a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_likely_topics = topic_distribution.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "862499ef-ca78-4283-8c41-b11e1195cc9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 4, ..., 0, 0, 6], dtype=int64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_likely_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "408bb3d6-40ea-4bc6-8a7d-f62c54f854b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['most_likely_topic'] = most_likely_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9dcbc2a5-3ca9-4d30-8440-60bc781b77f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>most_likely_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5164</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5165</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5166</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5167</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5168</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5169 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        v1                                                 v2  \\\n",
       "0      ham  Go until jurong point, crazy.. Available only ...   \n",
       "1      ham                      Ok lar... Joking wif u oni...   \n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3      ham  U dun say so early hor... U c already then say...   \n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "...    ...                                                ...   \n",
       "5164  spam  This is the 2nd time we have tried 2 contact u...   \n",
       "5165   ham              Will Ì_ b going to esplanade fr home?   \n",
       "5166   ham  Pity, * was in mood for that. So...any other s...   \n",
       "5167   ham  The guy did some bitching but I acted like i'd...   \n",
       "5168   ham                         Rofl. Its true to its name   \n",
       "\n",
       "      most_likely_topic  \n",
       "0                     0  \n",
       "1                     3  \n",
       "2                     4  \n",
       "3                     0  \n",
       "4                     0  \n",
       "...                 ...  \n",
       "5164                  4  \n",
       "5165                  5  \n",
       "5166                  0  \n",
       "5167                  0  \n",
       "5168                  6  \n",
       "\n",
       "[5169 rows x 3 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed70df7-ff4f-47b5-aa20-06b89bbdf1f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
