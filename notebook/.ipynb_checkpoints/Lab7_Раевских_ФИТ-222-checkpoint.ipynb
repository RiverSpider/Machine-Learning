{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e03287c-c859-4650-973a-92f1ce816c40",
   "metadata": {},
   "source": [
    "Лабораторная работа №7. \"Полносвязные нейронные сети (многослойный персептрон). Решение задач регрессии и классификации\"\n",
    "\n",
    "Задание №1.\n",
    "Решить задачи регрессии и классификации на данных в соответствии с Вашим индивидуальным вариантом (см. Лаб.работы №3, 4), используя полносвязные НС; реализовать НС посредством API Keras и фреймворка TensorFlow; оценить качество полученных моделей с помощью метрик.\n",
    "\n",
    "Задание №2.\n",
    "Разработать многослойный персептрон (MLP), с помощью которого можно решать задачи регрессии и классификации. Предусмотреть возможность использования таких функции активации, как sigmoid, tanh и relu; также предусмотреть возможность указать, сколько слоев нужно, сколько на каждом из них нейронов и какую функцию активации должен иметь слой. Реализовать обучение MLP методом обратного распространения ошибки; самостоятельно найти производные функций sigmoid, tanh и relu; реализовать классический градиентный спуск с возможностью указания шага.\n",
    "\n",
    "\n",
    "Дополнительное Задание №3*.\n",
    "1. Самостоятельно изучить отличия работы оптимизаторов Adam и RMSProp от классического градиентного спуска.\n",
    "2. Реализовать градиентный спуск с использованием указанных оптимизаторов; предусмотрите возможность использования реализованных вами оптими-заторов в Вашем персептроне."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0be2f7a-5bbb-46ad-a6ad-99f9e3bbc29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "615615fa-6fb3-4a09-8eb8-1b29330188a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../data')\n",
    "#Вариант 1\n",
    "df_regression = pd.read_csv('lab3.csv')\n",
    "df_classifier = pd.read_csv('lab4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d739913-7796-4d0c-844b-ace3e2e18fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "numeric_features_classifier = ['time','length'] \n",
    "df_classifier[numeric_features_classifier] = scaler.fit_transform(df_classifier[numeric_features_classifier])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1e6ccb60-242e-45d1-8930-0a945fae897e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y_classifier = df_classifier[\"delay\"]\n",
    "X_classifier = df_classifier.drop([\"delay\"], axis=1)\n",
    "X_classifier, _, y_classifier, _ = train_test_split(X_classifier, y_classifier, test_size=0.9, random_state=42)\n",
    "\n",
    "\n",
    "y_regression = df_regression[\"price(euro)\"]\n",
    "X_regression = df_regression.drop([\"price(euro)\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a6a95915-41e8-4f40-9f8e-9f840c53c5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import NearMiss\n",
    "nm = NearMiss()\n",
    "X_classifier, y_classifier = nm.fit_resample(X_classifier, y_classifier.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f57e5a94-1905-466d-bdda-fd691d23003c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_classifier, X_test_classifier, y_train_classifier, y_test_classifier = train_test_split(X_classifier, y_classifier, test_size=0.2)\n",
    "X_train_regression, X_test_regression, y_train_regression, y_test_regression = train_test_split(X_regression, y_regression, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6decf4f7-f44c-4984-9bf5-aa6c76f6f9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# для оценки качества решения задачи регрессии\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "# для оценки качества решения задачи классификации\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "caeb8452-3858-4e15-9f0b-d74a97441236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2ea0cf2-42e4-4a50-9e9e-f1df3eb62e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "646187f6-0c37-4b24-a293-37e79f6cf271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем модель, как набор последовательных слоев\n",
    "model_regression = tf.keras.Sequential(\n",
    "    [\n",
    "        # Dense - полносвязный слой (каждый нейрон следующего слоя связан со всеми нейронами предыдущего)\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\", input_shape=(939,)),\n",
    "        # на втором скрытом слое будет 32 нейрона\n",
    "        tf.keras.layers.Dense(32, activation=\"linear\"),\n",
    "        # Dropout позволяет внести фактор случайности - при обучении часть нейронов будет отключаться\n",
    "        # каждый нейрон, в данном случае, будет отключаться с вероятностью 0.1\n",
    "        tf.keras.layers.Dropout(0.1),\n",
    "        tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.1),\n",
    "        # на выходе один нейрон, функция активации не применяется\n",
    "        tf.keras.layers.Dense(1, activation=\"linear\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d242b45-cc52-4428-8dd6-764bb6fe3244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                60160     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 62785 (245.25 KB)\n",
      "Trainable params: 62785 (245.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# посмотрим, какая сеть у нас получилась\n",
    "model_regression.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1ade7d3-3ad9-4980-a07b-0aab615ed296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# компилируем\n",
    "model_regression.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.005), loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "298eddab-de08-400c-ba64-2c0768802e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_regression = X_train_regression.astype('float32')\n",
    "y_train_regression = y_train_regression.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9cf4b3e6-962a-4701-baf5-4c00c407b30f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x236d79b9790>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# обучаем, 10 эпох означает 10 проходов по обучающей выборке\n",
    "model_regression.fit(X_train_regression, y_train_regression, epochs=50, verbose=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30bb8011-978b-49c0-8789-6ca98728ae06",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_regression = X_train_regression.astype('float32')\n",
    "y_test_regression = y_train_regression.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "590d2263-33be-4159-9e93-eff2ac30b365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "752/752 [==============================] - 1s 952us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_regression = model_regression.predict(X_test_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ee5a393-6645-43c4-8103-11fb33611f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2992.0664\n",
      "15521305.0\n",
      "0.43372047006974\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "# оцениваем качество с помощью метрик\n",
    "print(mean_absolute_error(y_test_regression, y_pred_regression))\n",
    "print(mean_squared_error(y_test_regression, y_pred_regression))\n",
    "print(r2_score(y_test_regression, y_pred_regression))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ece31993-21e7-441f-ad8f-1c29827c5698",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Бинарная классификация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4beebfb5-9887-46f7-8ab9-8f3a5fca2bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_classification = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\", input_shape=(608,)),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.05),\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "        # используем 1 нейрон и sigmoid\n",
    "        tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1efb3060-8772-43eb-8aef-cd34a771e3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_classifier = X_train_classifier.astype('float32')\n",
    "y_train_classifier = y_train_classifier.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4806268b-98f6-4091-ba8a-20056cb89c83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x236aef7ca50>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# в качестве функции активации используется бинарная  кроссэнтропия\n",
    "model_classification.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=\"mse\")\n",
    "# verbose=None - не будет логов\n",
    "model_classification.fit(X_train_classifier, y_train_classifier, epochs=100, verbose=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "65c7c53b-a92a-4d3e-909c-099e16b28012",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raevs\\Desktop\\ML\\venv\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model_classification.save('models/NN_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3532da2b-fdf5-46a0-a55e-e010cb25eb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_classifier = X_test_classifier.astype('float32')\n",
    "y_test_classifier = y_test_classifier.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c8299cfa-8666-48cc-98d8-e68fc392c7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предсказание на тестовых данных\n",
    "y_pred_classifier = [np.argmax(pred) for pred in model_classification.predict(X_test_classifier, verbose=None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a5558d69-6bce-43cb-854c-e1b920bfa90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5060422960725075\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test_classifier, y_pred_classifier)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7698d98-daee-4927-842d-64bd62cbf84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_classifier, y_pred_classifier, zero_division=0))\n",
    "print(confusion_matrix(y_test_classifier, y_pred_classifier))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d53cc9d-c85c-4187-a2a3-ab8c2aa07a47",
   "metadata": {},
   "source": [
    "Задание №2. Разработать многослойный персептрон (MLP), с помощью которого можно решать задачи регрессии и классификации. Предусмотреть возможность использования таких функции активации, как sigmoid, tanh и relu; также предусмотреть возможность указать, сколько слоев нужно, сколько на каждом из них нейронов и какую функцию активации должен иметь слой. Реализовать обучение MLP методом обратного распространения ошибки; самостоятельно найти производные функций sigmoid, tanh и relu; реализовать классический градиентный спуск с возможностью указания шага."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c6118d4a-4da3-4a4d-b508-8760cc918bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MLP:\n",
    "    def __init__(self, layer_sizes, activation_functions):\n",
    "        self.num_layers = len(layer_sizes)\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.activation_functions = activation_functions\n",
    "        self.weights = [np.random.randn(layer_sizes[i], layer_sizes[i-1]) for i in range(1, self.num_layers)]\n",
    "        self.biases = [np.random.randn(layer_sizes[i], 1) for i in range(1, self.num_layers)]\n",
    "\n",
    "    def _sigmoid(self, x):\n",
    "        return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "    def _sigmoid_derivative(self, x):\n",
    "        return self._sigmoid(x) * (1 - self._sigmoid(x))\n",
    "\n",
    "    def _tanh(self, x):\n",
    "        return np.tanh(x)\n",
    "\n",
    "    def _tanh_derivative(self, x):\n",
    "        return 1 - np.tanh(x)**2\n",
    "\n",
    "    def _relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def _relu_derivative(self, x):\n",
    "        return np.where(x > 0, 1, 0)\n",
    "\n",
    "    def _feed_forward(self, x):\n",
    "        activations = [x]\n",
    "        zs = []\n",
    "        for i in range(self.num_layers - 1):\n",
    "            weight = self.weights[i]\n",
    "            bias = self.biases[i]\n",
    "            activation_fn = self.activation_functions[i]\n",
    "            z = np.dot(weight, activations[-1]) + bias\n",
    "            zs.append(z)\n",
    "            if activation_fn == 'sigmoid':\n",
    "                a = self._sigmoid(z)\n",
    "            elif activation_fn == 'tanh':\n",
    "                a = self._tanh(z)\n",
    "            elif activation_fn == 'relu':\n",
    "                a = self._relu(z)\n",
    "            activations.append(a)\n",
    "        return activations, zs\n",
    "\n",
    "    def _backpropagate(self, x, y):\n",
    "        delta_weights = [np.zeros(weight.shape) for weight in self.weights]\n",
    "        delta_biases = [np.zeros(bias.shape) for bias in self.biases]\n",
    "        activations, zs = self._feed_forward(x)\n",
    "        delta = (activations[-1] - y)  # derivative of the loss function\n",
    "        for i in range(self.num_layers - 2, -1, -1):\n",
    "            z = zs[i]\n",
    "            activation_fn = self.activation_functions[i]\n",
    "            if activation_fn == 'sigmoid':\n",
    "                derivative = self._sigmoid_derivative(z)\n",
    "            elif activation_fn == 'tanh':\n",
    "                derivative = self._tanh_derivative(z)\n",
    "            elif activation_fn == 'relu':\n",
    "                derivative = self._relu_derivative(z)\n",
    "            delta_weights[i] = np.dot(delta, activations[i].T)\n",
    "            delta_biases[i] = delta\n",
    "            delta = np.dot(self.weights[i].T, delta) * derivative\n",
    "        return delta_weights, delta_biases\n",
    "\n",
    "    def train(self, X_train, y_train, learning_rate, num_epochs):\n",
    "        for epoch in range(num_epochs):\n",
    "            for x, y in zip(X_train, y_train):\n",
    "                x = np.array(x, ndmin=2).T\n",
    "                y = np.array(y, ndmin=2).T\n",
    "                delta_weights, delta_biases = self._backpropagate(x, y)\n",
    "                self.weights = [weight - learning_rate * d_weight for weight, d_weight in zip(self.weights, delta_weights)]\n",
    "                self.biases = [bias - learning_rate * d_bias for bias, d_bias in zip(self.biases, delta_biases)]\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        predictions = []\n",
    "        for x in X_test:\n",
    "            x = np.array(x, ndmin=2).T\n",
    "            activations, _ = self._feed_forward(x)\n",
    "            predictions.append(activations[-1])\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "3ea7752f-c96f-4aa2-8882-1a185c694757",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raevs\\AppData\\Local\\Temp\\ipykernel_17836\\2927836980.py:12: RuntimeWarning: overflow encountered in exp\n",
      "  return 1.0 / (1.0 + np.exp(-x))\n"
     ]
    }
   ],
   "source": [
    "X_train_regression = np.asarray(X_train_regression, dtype=np.float64)\n",
    "y_train_regression = np.asarray(y_train_regression, dtype=np.float64).reshape(-1, 1)\n",
    "# Создание объекта MLP для регрессии\n",
    "mlp_regression = MLP([939, 1, 1], ['sigmoid', 'sigmoid'])\n",
    "\n",
    "# Обучаем модель\n",
    "mlp_regression.train(X_train_regression, y_train_regression, learning_rate=0.05, num_epochs=10)\n",
    "\n",
    "X_test_regression = np.asarray(X_test_regression, dtype=np.float64)\n",
    "# Получаем предсказания модели\n",
    "predictions_regression = mlp_regression.predict(X_test_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "46111471-197f-40fd-a6d3-ba74afab9586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2992.0664\n",
      "15521305.0\n",
      "0.43372047006974\n"
     ]
    }
   ],
   "source": [
    "y_test_regression = np.asarray(y_test_regression, dtype=np.float64).reshape(-1, 1)\n",
    "from sklearn.metrics import r2_score\n",
    "print(mean_absolute_error(y_test_regression, predictions_regression))\n",
    "print(mean_squared_error(y_test_regression, predictions_regression))\n",
    "print(r2_score(y_test_regression, predictions_regression))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "d7c2a946-f945-4c1b-889f-cf61c65ace0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_classifier = np.asarray(X_train_classifier, dtype=np.float64)\n",
    "y_train_classifier = np.asarray(y_train_classifier, dtype=np.float64).reshape(-1, 1)\n",
    "mlp_classifier = MLP([608, 1, 1, 1], ['tanh', 'relu', 'sigmoid'])\n",
    "\n",
    "mlp_classifier.train(X_train_classifier, y_train_classifier, learning_rate=0.05, num_epochs=10)\n",
    "\n",
    "X_test_classifier = np.asarray(X_test_classifier, dtype=np.float64)\n",
    "# Получаем предсказания модели\n",
    "predictions_classifier = mlp_classifier.predict(X_test_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "a444b41b-1c61-4366-9d40-a89f09503d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5060422960725075\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_test_classifier = np.asarray(y_test_classifier, dtype=np.float64)\n",
    "accuracy = accuracy_score(y_test_classifier, predictions_classifier)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947cf100-58e8-4b2f-9160-98b2f86af97a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
