{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e03287c-c859-4650-973a-92f1ce816c40",
   "metadata": {},
   "source": [
    "Лабораторная работа №7. \"Полносвязные нейронные сети (многослойный персептрон). Решение задач регрессии и классификации\"\n",
    "\n",
    "Задание №1.\n",
    "Решить задачи регрессии и классификации на данных в соответствии с Вашим индивидуальным вариантом (см. Лаб.работы №3, 4), используя полносвязные НС; реализовать НС посредством API Keras и фреймворка TensorFlow; оценить качество полученных моделей с помощью метрик.\n",
    "\n",
    "Задание №2.\n",
    "Разработать многослойный персептрон (MLP), с помощью которого можно решать задачи регрессии и классификации. Предусмотреть возможность использования таких функции активации, как sigmoid, tanh и relu; также предусмотреть возможность указать, сколько слоев нужно, сколько на каждом из них нейронов и какую функцию активации должен иметь слой. Реализовать обучение MLP методом обратного распространения ошибки; самостоятельно найти производные функций sigmoid, tanh и relu; реализовать классический градиентный спуск с возможностью указания шага.\n",
    "\n",
    "\n",
    "Дополнительное Задание №3*.\n",
    "1. Самостоятельно изучить отличия работы оптимизаторов Adam и RMSProp от классического градиентного спуска.\n",
    "2. Реализовать градиентный спуск с использованием указанных оптимизаторов; предусмотрите возможность использования реализованных вами оптими-заторов в Вашем персептроне."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0be2f7a-5bbb-46ad-a6ad-99f9e3bbc29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "615615fa-6fb3-4a09-8eb8-1b29330188a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../data')\n",
    "#Вариант 1\n",
    "df_regression = pd.read_csv('lab3.csv')\n",
    "df_classifier = pd.read_csv('lab4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d739913-7796-4d0c-844b-ace3e2e18fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "numeric_features_classifier = ['time','length'] \n",
    "df_classifier[numeric_features_classifier] = scaler.fit_transform(df_classifier[numeric_features_classifier])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e6ccb60-242e-45d1-8930-0a945fae897e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y_classifier = df_classifier[\"delay\"]\n",
    "X_classifier = df_classifier.drop([\"delay\"], axis=1)\n",
    "X_classifier, _, y_classifier, _ = train_test_split(X_classifier, y_classifier, test_size=0.9, random_state=42)\n",
    "\n",
    "\n",
    "y_regression = df_regression[\"price(euro)\"]\n",
    "X_regression = df_regression.drop([\"price(euro)\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6a95915-41e8-4f40-9f8e-9f840c53c5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import NearMiss\n",
    "nm = NearMiss()\n",
    "X_classifier, y_classifier = nm.fit_resample(X_classifier, y_classifier.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f57e5a94-1905-466d-bdda-fd691d23003c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_classifier, X_test_classifier, y_train_classifier, y_test_classifier = train_test_split(X_classifier, y_classifier, test_size=0.2)\n",
    "X_train_regression, X_test_regression, y_train_regression, y_test_regression = train_test_split(X_regression, y_regression, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6decf4f7-f44c-4984-9bf5-aa6c76f6f9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# для оценки качества решения задачи регрессии\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "# для оценки качества решения задачи классификации\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "caeb8452-3858-4e15-9f0b-d74a97441236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2ea0cf2-42e4-4a50-9e9e-f1df3eb62e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "646187f6-0c37-4b24-a293-37e79f6cf271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем модель, как набор последовательных слоев\n",
    "model_regression = tf.keras.Sequential(\n",
    "    [\n",
    "        # Dense - полносвязный слой (каждый нейрон следующего слоя связан со всеми нейронами предыдущего)\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\", input_shape=(939,)),\n",
    "        # на втором скрытом слое будет 32 нейрона\n",
    "        tf.keras.layers.Dense(32, activation=\"linear\"),\n",
    "        # Dropout позволяет внести фактор случайности - при обучении часть нейронов будет отключаться\n",
    "        # каждый нейрон, в данном случае, будет отключаться с вероятностью 0.1\n",
    "        tf.keras.layers.Dropout(0.1),\n",
    "        tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.1),\n",
    "        # на выходе один нейрон, функция активации не применяется\n",
    "        tf.keras.layers.Dense(1, activation=\"linear\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d242b45-cc52-4428-8dd6-764bb6fe3244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                60160     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 62785 (245.25 KB)\n",
      "Trainable params: 62785 (245.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# посмотрим, какая сеть у нас получилась\n",
    "model_regression.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1ade7d3-3ad9-4980-a07b-0aab615ed296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# компилируем\n",
    "model_regression.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.005), loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "298eddab-de08-400c-ba64-2c0768802e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_regression = X_train_regression.astype('float32')\n",
    "y_train_regression = y_train_regression.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9cf4b3e6-962a-4701-baf5-4c00c407b30f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x236d79b9790>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# обучаем, 10 эпох означает 10 проходов по обучающей выборке\n",
    "model_regression.fit(X_train_regression, y_train_regression, epochs=50, verbose=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30bb8011-978b-49c0-8789-6ca98728ae06",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_regression = X_train_regression.astype('float32')\n",
    "y_test_regression = y_train_regression.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "590d2263-33be-4159-9e93-eff2ac30b365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "752/752 [==============================] - 1s 952us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_regression = model_regression.predict(X_test_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ee5a393-6645-43c4-8103-11fb33611f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2992.0664\n",
      "15521305.0\n",
      "0.43372047006974\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "# оцениваем качество с помощью метрик\n",
    "print(mean_absolute_error(y_test_regression, y_pred_regression))\n",
    "print(mean_squared_error(y_test_regression, y_pred_regression))\n",
    "print(r2_score(y_test_regression, y_pred_regression))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ece31993-21e7-441f-ad8f-1c29827c5698",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Бинарная классификация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4beebfb5-9887-46f7-8ab9-8f3a5fca2bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_classification = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\", input_shape=(608,)),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.05),\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "        # используем 1 нейрон и sigmoid\n",
    "        tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1efb3060-8772-43eb-8aef-cd34a771e3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_classifier = X_train_classifier.astype('float32')\n",
    "y_train_classifier = y_train_classifier.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4806268b-98f6-4091-ba8a-20056cb89c83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x236aef7ca50>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# в качестве функции активации используется бинарная  кроссэнтропия\n",
    "model_classification.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=\"mse\")\n",
    "# verbose=None - не будет логов\n",
    "model_classification.fit(X_train_classifier, y_train_classifier, epochs=100, verbose=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "65c7c53b-a92a-4d3e-909c-099e16b28012",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raevs\\Desktop\\ML\\venv\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model_classification.save('models/NN_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3532da2b-fdf5-46a0-a55e-e010cb25eb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_classifier = X_test_classifier.astype('float32')\n",
    "y_test_classifier = y_test_classifier.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c8299cfa-8666-48cc-98d8-e68fc392c7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предсказание на тестовых данных\n",
    "y_pred_classifier = [np.argmax(pred) for pred in model_classification.predict(X_test_classifier, verbose=None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a5558d69-6bce-43cb-854c-e1b920bfa90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5060422960725075\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test_classifier, y_pred_classifier)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7698d98-daee-4927-842d-64bd62cbf84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_classifier, y_pred_classifier, zero_division=0))\n",
    "print(confusion_matrix(y_test_classifier, y_pred_classifier))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d53cc9d-c85c-4187-a2a3-ab8c2aa07a47",
   "metadata": {},
   "source": [
    "Задание №2. Разработать многослойный персептрон (MLP), с помощью которого можно решать задачи регрессии и классификации. Предусмотреть возможность использования таких функции активации, как sigmoid, tanh и relu; также предусмотреть возможность указать, сколько слоев нужно, сколько на каждом из них нейронов и какую функцию активации должен иметь слой. Реализовать обучение MLP методом обратного распространения ошибки; самостоятельно найти производные функций sigmoid, tanh и relu; реализовать классический градиентный спуск с возможностью указания шага."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103b1bc0-afcf-49c2-be89-77a014fb6dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "\n",
    "class MLP:\n",
    "    def __init__(self, input_size, hidden_layers, output_size, activations):\n",
    "        \"\"\"\n",
    "        :param input_size: Размер входного слоя\n",
    "        :param hidden_layers: Список, содержащий количество нейронов в каждом скрытом слое\n",
    "        :param output_size: Размер выходного слоя\n",
    "        :param activations: Список функций активации для каждого слоя\n",
    "        :param learning_rate: Скорость обучения для градиентного спуска\n",
    "        \"\"\"\n",
    "        self.input_size = input_size\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.output_size = output_size\n",
    "        self.activations = activations\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # Инициализация весов и смещений\n",
    "        self.weights, self.biases = self.initialize_parameters()\n",
    "\n",
    "    def initialize_parameters(self):\n",
    "        \"\"\"\n",
    "        Инициализация весов и смещений\n",
    "        \"\"\"\n",
    "        sizes = [self.input_size] + self.hidden_layers + [self.output_size]\n",
    "        weights = [np.random.randn(sizes[i], sizes[i+1]) for i in range(len(sizes)-1)]\n",
    "        biases = [np.zeros((1, sizes[i+1])) for i in range(len(sizes)-1)]\n",
    "        return weights, biases\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        \"\"\"\n",
    "        Сигмоидная функция активации\n",
    "        \"\"\"\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def sigmoid_derivative(self, x):\n",
    "        \"\"\"\n",
    "        Производная сигмоидной функции\n",
    "        \"\"\"\n",
    "        return self.sigmoid(x) * (1 - self.sigmoid(x))\n",
    "\n",
    "    def tanh(self, x):\n",
    "        \"\"\"\n",
    "        Гиперболический тангенс\n",
    "        \"\"\"\n",
    "        return np.tanh(x)\n",
    "\n",
    "    def tanh_derivative(self, x):\n",
    "        \"\"\"\n",
    "        Производная гиперболического тангенса\n",
    "        \"\"\"\n",
    "        return 1 - np.tanh(x)**2\n",
    "\n",
    "    def relu(self, x):\n",
    "        \"\"\"\n",
    "        Функция активации ReLU\n",
    "        \"\"\"\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def relu_derivative(self, x):\n",
    "        \"\"\"\n",
    "        Производная функции активации ReLU\n",
    "        \"\"\"\n",
    "        return np.where(x > 0, 1, 0)\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Прямое распространение (forward pass)\n",
    "        \"\"\"\n",
    "        self.z_values = []\n",
    "        self.activations_values = []\n",
    "\n",
    "        # Входной слой\n",
    "        a = X\n",
    "        self.activations_values.append(a)\n",
    "\n",
    "        # Скрытые слои\n",
    "        for i in range(len(self.hidden_layers)):\n",
    "            z = np.dot(a, self.weights[i]) + self.biases[i]\n",
    "            self.z_values.append(z)\n",
    "            a = self.activations[i](z)\n",
    "            self.activations_values.append(a)\n",
    "\n",
    "        # Выходной слой\n",
    "        z = np.dot(a, self.weights[-1]) + self.biases[-1]\n",
    "        self.z_values.append(z)\n",
    "        a = self.sigmoid(z)  # Для задачи регрессии можно использовать другие функции активации\n",
    "        self.activations_values.append(a)\n",
    "\n",
    "        return a\n",
    "\n",
    "    def backward(self, X, y):\n",
    "        \"\"\"\n",
    "        Обратное распространение ошибки (backpropagation)\n",
    "        \"\"\"\n",
    "        m = X.shape[0]\n",
    "        delta = self.activations_values[-1] - y\n",
    "        dz = delta * self.sigmoid_derivative(self.z_values[-1])\n",
    "        dw = np.dot(self.activations_values[-2].T, dz) / m\n",
    "        db = np.sum(dz, axis=0, keepdims=True) / m\n",
    "        self.weights[-1] -= self.learning_rate * dw\n",
    "        self.biases[-1] -= self.learning_rate * db\n",
    "\n",
    "        for i in range(len(self.hidden_layers), 0, -1):\n",
    "            delta = np.dot(dz, self.weights[i].T)\n",
    "            dz = delta * self.activations[i-1](self.z_values[i-1])\n",
    "            dw = np.dot(self.activations_values[i-2].T, dz) / m\n",
    "            db = np.sum(dz, axis=0, keepdims=True) / m\n",
    "            self.weights[i-1] -= self.learning_rate * dw\n",
    "            self.biases[i-1] -= self.learning_rate * db\n",
    "\n",
    "    def train(self, X, y, epochs):\n",
    "        \"\"\"\n",
    "        Обучение модели\n",
    "        \"\"\"\n",
    "        for epoch in range(epochs):\n",
    "            output = self.forward(X)\n",
    "            self.backward(X, y)\n",
    "\n",
    "            if epoch % 100 == 0:\n",
    "                loss = np.mean(0.5 * (output - y)**2)\n",
    "                print(f\"Epoch {epoch}, Loss: {loss}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Предсказание\n",
    "        \"\"\"\n",
    "        return self.forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fd0b41-f077-4bf8-b0a5-e868b7ae66e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_regressor = MLP(input_size=939, hidden_layers=[24050,939], output_size=1, activations=[np.tanh, expit])\n",
    "mlp_regressor.train(X_train_regression, y_train_regression, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cde8cb-51a0-4ff4-abf4-2d92f79c15fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_cattle_population():\n",
    "    initial_cattle_population = 74\n",
    "    initial_wolf_population = 67\n",
    "    wolf_shooting = 36\n",
    "    final_wolf_population = 44\n",
    "    final_cattle_population = 107\n",
    "\n",
    "    # Расчет максимальной численности скота\n",
    "    max_cattle_population = (final_cattle_population * (initial_wolf_population - wolf_shooting)) / (final_wolf_population - wolf_shooting)\n",
    "\n",
    "    return int(max_cattle_population)\n",
    "\n",
    "# Вызов функции и вывод результата\n",
    "result = find_max_cattle_population()\n",
    "print(\"Максимальное количество голов крупного рогатого скота за указанный период составляет: \", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496371e2-70b3-430c-8a99-ef82192715b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.constants import epsilon_0\n",
    "\n",
    "# Дано\n",
    "V0 = 5.0  # Напряжение на обкладках в вольтах\n",
    "D = 0.4e-3  # Расстояние между обкладками в метрах\n",
    "p0 = 1e4  # Объемная плотность заряда p0 в кл/м^5\n",
    "e = 4.04e-12  # Диэлектрическая проницаемость в Ф/м\n",
    "N = 1000  # Количество точек для аппроксимации\n",
    "\n",
    "# Шаг по координате X\n",
    "dx = D / N\n",
    "\n",
    "# Инициализация массива для хранения значений потенциала\n",
    "phi = np.zeros(N)\n",
    "\n",
    "# Задание начальных и граничных условий\n",
    "phi[0] = 0  # Потенциал на заземленной обкладке\n",
    "phi[-1] = V0  # Потенциал на поданной напряжением обкладке\n",
    "\n",
    "# Аппроксимация дифференциального уравнения методом конечных разностей\n",
    "for i in range(1, N - 1):\n",
    "    x = i * dx\n",
    "    p_x = p0 * (x - D) ** 2\n",
    "    phi[i + 1] = 2 * phi[i] - phi[i - 1] + (dx ** 2) * p_x / e\n",
    "\n",
    "# Находим значение потенциала в центре конденсатора\n",
    "phi_center = phi[N // 2]\n",
    "\n",
    "# Вывод результата\n",
    "print(f\"Значение потенциала в центре конденсатора: {phi_center:.1f} В\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6118d4a-4da3-4a4d-b508-8760cc918bab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
